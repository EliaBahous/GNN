{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AadjR9tEd5br",
        "outputId": "d5614f23-5f62-449c-fd4a-54599db94209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.12.6\n",
            "Requirement already satisfied: ipykernel in /Users/elia/Library/Python/3.12/lib/python/site-packages (6.30.1)\n",
            "Requirement already satisfied: appnope>=0.1.2 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (0.1.4)\n",
            "Requirement already satisfied: comm>=0.1.1 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (0.2.3)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (1.8.17)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (9.6.0)\n",
            "Requirement already satisfied: jupyter-client>=8.0.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (5.8.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio>=1.4 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: packaging>=22 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (25.0)\n",
            "Requirement already satisfied: psutil>=5.7 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (7.1.0)\n",
            "Requirement already satisfied: pyzmq>=25 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (27.1.0)\n",
            "Requirement already satisfied: tornado>=6.2 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (6.5.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipykernel) (5.14.3)\n",
            "Requirement already satisfied: decorator in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
            "Requirement already satisfied: stack_data in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in /Users/elia/Library/Python/3.12/lib/python/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.4.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /Users/elia/Library/Python/3.12/lib/python/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
            "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (25.2)\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!python3.12 --version\n",
        "!python3.12 -m pip install ipykernel\n",
        "!python3.12 -m pip install --upgrade pip\n",
        "!python3.12 -m pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JEFHLwLAN7BL",
        "outputId": "a65ac3ff-c9b0-40cd-aa32-84cb08c98895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.8.0\n",
            "Uninstalling torch-2.8.0:\n",
            "  Successfully uninstalled torch-2.8.0\n",
            "Found existing installation: torch_scatter 2.1.2\n",
            "Uninstalling torch_scatter-2.1.2:\n",
            "  Successfully uninstalled torch_scatter-2.1.2\n",
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cpu/torch-2.8.0-cp312-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.23.0)\n",
            "Requirement already satisfied: torchaudio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
            "Collecting numpy (from torchvision)\n",
            "  Using cached numpy-2.3.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
            "Using cached https://download.pytorch.org/whl/cpu/torch-2.8.0-cp312-none-macosx_11_0_arm64.whl (73.5 MB)\n",
            "Using cached numpy-2.3.3-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
            "Installing collected packages: numpy, torch\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torch]━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
            "\u001b[1A\u001b[2KSuccessfully installed numpy-2.3.3 torch-2.8.0\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip uninstall torch torch_scatter -y\n",
        "!python3 -m pip uninstall numpy -y\n",
        "!python3 -m pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcpu/torch_scatter-2.1.2-cp312-cp312-macosx_10_13_universal2.whl (813 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.2/813.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Requirement already satisfied: torch-geometric in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch-geometric) (2025.9.0)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch-geometric) (2.3.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from torch-geometric) (7.1.0)\n",
            "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch-geometric) (2.32.5)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->torch-geometric) (2024.12.14)\n",
            "Requirement already satisfied: numba in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.62.1)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from numba) (0.45.1)\n",
            "Requirement already satisfied: numpy<2.4,>=1.22 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from numba) (2.3.3)\n"
          ]
        }
      ],
      "source": [
        "!export MACOSX_DEPLOYMENT_TARGET=10.14\n",
        "!python3 -m pip install --no-cache-dir torch-scatter -f https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
        "!python3 -m pip install torch-geometric\n",
        "!python3 -m pip install numba\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F4NYOeqIQE8f",
        "outputId": "151529cf-1c67-4a43-d6ca-82afb0a982d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pykeops in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.3)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pykeops) (2.3.3)\n",
            "Requirement already satisfied: pybind11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pykeops) (3.0.1)\n",
            "Requirement already satisfied: keopscore==2.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pykeops) (2.3)\n",
            "Collecting numpy==2.0.2\n",
            "  Using cached numpy-2.0.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
            "Using cached numpy-2.0.2-cp312-cp312-macosx_14_0_arm64.whl (5.0 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.3\n",
            "    Uninstalling numpy-2.3.3:\n",
            "      Successfully uninstalled numpy-2.3.3\n",
            "Successfully installed numpy-2.0.2\n",
            "Requirement already satisfied: ogb==1.3.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.3.6)\n",
            "Requirement already satisfied: torchdiffeq==0.2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.2.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ogb==1.3.6) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ogb==1.3.6) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ogb==1.3.6) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ogb==1.3.6) (1.7.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ogb==1.3.6) (2.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ogb==1.3.6) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ogb==1.3.6) (2.5.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ogb==1.3.6) (0.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchdiffeq==0.2.5) (1.16.2)\n",
            "Requirement already satisfied: setuptools>=44 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outdated>=0.2.0->ogb==1.3.6) (80.9.0)\n",
            "Requirement already satisfied: littleutils in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outdated>=0.2.0->ogb==1.3.6) (0.2.4)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from outdated>=0.2.0->ogb==1.3.6) (2.32.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from pandas>=0.24.0->ogb==1.3.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.24.0->ogb==1.3.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.24.0->ogb==1.3.6) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn>=0.20.0->ogb==1.3.6) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn>=0.20.0->ogb==1.3.6) (3.6.0)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.6.0->ogb==1.3.6) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.6.0->ogb==1.3.6) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.6.0->ogb==1.3.6) (1.14.0)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.6.0->ogb==1.3.6) (3.5)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.6.0->ogb==1.3.6) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.6.0->ogb==1.3.6) (2025.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.6.0->ogb==1.3.6) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.6.0->ogb==1.3.6) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->outdated>=0.2.0->ogb==1.3.6) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->outdated>=0.2.0->ogb==1.3.6) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->outdated>=0.2.0->ogb==1.3.6) (2024.12.14)\n",
            "Requirement already satisfied: pyvis in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.2)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from pyvis) (9.6.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyvis) (3.1.6)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyvis) (4.1.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyvis) (3.5)\n",
            "Requirement already satisfied: decorator in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=5.3.0->pyvis) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=5.3.0->pyvis) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=5.3.0->pyvis) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=5.3.0->pyvis) (2.19.2)\n",
            "Requirement already satisfied: stack_data in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=5.3.0->pyvis) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
            "Requirement already satisfied: wcwidth in /Users/elia/Library/Python/3.12/lib/python/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.14)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=2.9.6->pyvis) (3.0.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from stack_data->ipython>=5.3.0->pyvis) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /Users/elia/Library/Python/3.12/lib/python/site-packages (from stack_data->ipython>=5.3.0->pyvis) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /Users/elia/Library/Python/3.12/lib/python/site-packages (from stack_data->ipython>=5.3.0->pyvis) (0.2.3)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install pykeops\n",
        "!python3 -m pip install numpy==2.0.2\n",
        "!python3 -m pip install ogb==1.3.6 torchdiffeq==0.2.5\n",
        "!python3 -m pip install pyvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSE7nNchv8gs",
        "outputId": "6222c0c0-ddc2-462d-dd95-9d4f7c541c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from importlib import reload\n",
        "\n",
        "import data as dt\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from GNN import GNN\n",
        "from mutual import get_optimizer, train\n",
        "from mutual import test as test_model\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohH8tQNEvZr1"
      },
      "outputs": [],
      "source": [
        "# best_params_dict = {'Cora': {'M_nodes': 64, 'adaptive': False, 'add_source': True, 'adjoint': False, 'adjoint_method': 'adaptive_heun', 'adjoint_step_size': 1, 'alpha': 1.0, 'alpha_dim': 'sc', 'att_samp_pct': 1, 'attention_dim': 128, 'attention_norm_idx': 1, 'attention_rewiring': False, 'attention_type': 'scaled_dot', 'augment': False, 'baseline': False, 'batch_norm': False, 'beltrami': False, 'beta_dim': 'sc', 'block': 'attention', 'cpus': 1, 'data_norm': 'rw', 'dataset': 'Cora', 'decay': 0.00507685443154266, 'directional_penalty': None, 'dropout': 0.046878964627763316, 'dt': 0.001, 'dt_min': 1e-05, 'epoch': 100, 'exact': True, 'fc_out': False, 'feat_hidden_dim': 64, 'function': 'laplacian', 'gdc_avg_degree': 64, 'gdc_k': 64, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_threshold': 0.01, 'gpus': 0.5, 'grace_period': 20, 'heads': 8, 'heat_time': 3.0, 'hidden_dim': 80, 'input_dropout': 0.5, 'jacobian_norm2': None, 'kinetic_energy': None, 'label_rate': 0.5, 'leaky_relu_slope': 0.2, 'lr': 0.022924849756740397, 'max_epochs': 1000, 'max_iters': 100, 'max_nfe': 2000, 'method': 'dopri5', 'metric': 'accuracy', 'mix_features': False, 'name': 'cora_beltrami_splits', 'new_edges': 'random', 'no_alpha_sigmoid': False, 'not_lcc': True, 'num_init': 1, 'num_samples': 1000, 'num_splits': 2, 'ode_blocks': 1, 'optimizer': 'adamax', 'patience': 100, 'pos_enc_hidden_dim': 16, 'pos_enc_orientation': 'row', 'pos_enc_type': 'GDC', 'ppr_alpha': 0.05, 'reduction_factor': 10, 'regularise': False, 'reweight_attention': False, 'rewire_KNN': False, 'rewire_KNN_T': 'T0', 'rewire_KNN_epoch': 10, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'rewiring': None, 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'self_loop_weight': 1, 'sparsify': 'S_hat', 'square_plus': True, 'step_size': 1, 'threshold_type': 'addD_rvR', 'time': 18.294754260552843, 'tol_scale': 821.9773048827274, 'tol_scale_adjoint': 1.0, 'total_deriv': None, 'use_cora_defaults': False, 'use_flux': False, 'use_labels': False, 'use_lcc': True, 'use_mlp': False},\n",
        "#                     'Citeseer': {'M_nodes': 64, 'adaptive': False, 'add_source': True, 'adjoint': False, 'adjoint_method': 'adaptive_heun', 'adjoint_step_size': 1, 'alpha': 1.0, 'alpha_dim': 'sc', 'att_samp_pct': 1, 'attention_dim': 32, 'attention_norm_idx': 1, 'attention_rewiring': False, 'attention_type': 'exp_kernel', 'augment': False, 'baseline': False, 'batch_norm': False, 'beltrami': False, 'beta_dim': 'sc', 'block': 'attention', 'cpus': 1, 'data_norm': 'rw', 'dataset': 'Citeseer', 'decay': 0.1, 'directional_penalty': None, 'dropout': 0.7488085003122172, 'dt': 0.001, 'dt_min': 1e-05, 'epoch': 250, 'exact': True, 'fc_out': False, 'feat_hidden_dim': 64, 'function': 'laplacian', 'gdc_avg_degree': 64, 'gdc_k': 128, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_threshold': 0.01, 'gpus': 1.0, 'grace_period': 20, 'heads': 8, 'heat_time': 3.0, 'hidden_dim': 80, 'input_dropout': 0.6803233752085334, 'jacobian_norm2': None, 'kinetic_energy': None, 'label_rate': 0.5, 'leaky_relu_slope': 0.5825086997804176, 'lr': 0.00863585231323069, 'max_epochs': 1000, 'max_iters': 100, 'max_nfe': 3000, 'method': 'dopri5', 'metric': 'accuracy', 'mix_features': False, 'name': 'Citeseer_beltrami_1_KNN', 'new_edges': 'random', 'no_alpha_sigmoid': False, 'not_lcc': True, 'num_class': 6, 'num_feature': 3703, 'num_init': 2, 'num_nodes': 2120, 'num_samples': 400, 'num_splits': 1, 'ode_blocks': 1, 'optimizer': 'adam', 'patience': 100, 'pos_enc_dim': 'row', 'pos_enc_hidden_dim': 16, 'ppr_alpha': 0.05, 'reduction_factor': 4, 'regularise': False, 'reweight_attention': False, 'rewire_KNN': False, 'rewire_KNN_epoch': 10, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'rewiring': None, 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'self_loop_weight': 1, 'sparsify': 'S_hat', 'square_plus': True, 'step_size': 1, 'threshold_type': 'addD_rvR', 'time': 7.874113442879092, 'tol_scale': 2.9010446330432815, 'tol_scale_adjoint': 1.0, 'total_deriv': None, 'use_cora_defaults': False, 'use_flux': False, 'use_labels': False, 'use_lcc': True, 'use_mlp': False},\n",
        "#                     'Pubmed': {'M_nodes': 64, 'adaptive': False, 'add_source': True, 'adjoint': True, 'adjoint_method': 'adaptive_heun', 'adjoint_step_size': 1, 'alpha': 1.0, 'alpha_dim': 'sc', 'att_samp_pct': 1, 'attention_dim': 16, 'attention_norm_idx': 0, 'attention_rewiring': False, 'attention_type': 'cosine_sim', 'augment': False, 'baseline': False, 'batch_norm': False, 'beltrami': False, 'beta_dim': 'sc', 'block': 'attention', 'cpus': 1, 'data_norm': 'rw', 'dataset': 'Pubmed', 'decay': 0.0018236722171703636, 'directional_penalty': None, 'dropout': 0.07191100715473969, 'dt': 0.001, 'dt_min': 1e-05, 'epoch': 600, 'exact': False, 'fc_out': False, 'feat_hidden_dim': 64, 'function': 'laplacian', 'gdc_avg_degree': 64, 'gdc_k': 64, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_threshold': 0.01, 'gpus': 1.0, 'grace_period': 20, 'heads': 1, 'heat_time': 3.0, 'hidden_dim': 128, 'input_dropout': 0.5, 'jacobian_norm2': None, 'kinetic_energy': None, 'label_rate': 0.5, 'leaky_relu_slope': 0.2, 'lr': 0.014669345840305131, 'max_epochs': 1000, 'max_iters': 100, 'max_nfe': 5000, 'method': 'dopri5', 'metric': 'test_acc', 'mix_features': False, 'name': None, 'new_edges': 'random', 'no_alpha_sigmoid': False, 'not_lcc': True, 'num_init': 1, 'num_samples': 400, 'num_splits': 8, 'ode_blocks': 1, 'optimizer': 'adamax', 'patience': 100, 'pos_enc_dim': 'row', 'pos_enc_hidden_dim': 16, 'ppr_alpha': 0.05, 'reduction_factor': 10, 'regularise': False, 'reweight_attention': False, 'rewire_KNN': False, 'rewire_KNN_T': 'T0', 'rewire_KNN_epoch': 10, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'rewiring': None, 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'self_loop_weight': 1, 'sparsify': 'S_hat', 'square_plus': True, 'step_size': 1, 'threshold_type': 'addD_rvR', 'time': 12.942327880200853, 'tol_scale': 1991.0688305523001, 'tol_scale_adjoint': 16324.368093998313, 'total_deriv': None, 'use_cora_defaults': False, 'use_flux': False, 'use_labels': False, 'use_lcc': True, 'use_mlp': False, 'folder': 'pubmed_linear_att_beltrami_adj2', 'index': 0, 'run_with_KNN': False, 'change_att_sim_type': False, 'reps': 1, 'max_test_steps': 100, 'no_early': True, 'earlystopxT': 5.0, 'pos_enc_csv': False, 'pos_enc_type': 'GDC'},\n",
        "#                     'CoauthorCS': {'M_nodes': 64, 'adaptive': False, 'add_source': False, 'adjoint': True, 'adjoint_method': 'dopri5', 'adjoint_step_size': 1, 'alpha': 1.0, 'alpha_dim': 'sc', 'att_samp_pct': 1, 'attention_dim': 8, 'attention_norm_idx': 1, 'attention_rewiring': False, 'attention_type': 'scaled_dot', 'augment': False, 'baseline': False, 'batch_norm': False, 'beltrami': False, 'beta_dim': 'sc', 'block': 'attention', 'cpus': 1, 'data_norm': 'rw', 'dataset': 'CoauthorCS', 'decay': 0.004738413087298854, 'directional_penalty': None, 'dropout': 0.6857774850321, 'dt': 0.001, 'dt_min': 1e-05, 'edge_sampling': False, 'edge_sampling_T': 'T0', 'edge_sampling_add': 0.05, 'edge_sampling_epoch': 5, 'edge_sampling_online': False, 'edge_sampling_online_reps': 4, 'edge_sampling_rmv': 0.05, 'edge_sampling_space': 'pos_distance', 'edge_sampling_sym': False, 'epoch': 250, 'exact': False, 'fa_layer': False, 'fc_out': False, 'feat_hidden_dim': 128, 'function': 'laplacian', 'gdc_avg_degree': 64, 'gdc_k': 64, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_threshold': 0.0001, 'gpus': 1, 'grace_period': 20, 'heads': 4, 'heat_time': 3.0, 'hidden_dim': 16, 'input_dropout': 0.5275042493231822, 'jacobian_norm2': None, 'kinetic_energy': None, 'label_rate': 0.5, 'leaky_relu_slope': 0.7181389780997276, 'lr': 0.0009342860080741642, 'max_iters': 100, 'max_nfe': 3000, 'method': 'dopri5', 'metric': 'accuracy', 'mix_features': False, 'name': 'CoauthorCS_final_tune_posencGDC', 'new_edges': 'random', 'no_alpha_sigmoid': False, 'not_lcc': True, 'num_init': 1, 'num_samples': 400, 'num_splits': 4, 'ode_blocks': 1, 'optimizer': 'rmsprop', 'pos_dist_quantile': 0.001, 'pos_enc_csv': False, 'pos_enc_hidden_dim': 32, 'pos_enc_orientation': 'row', 'pos_enc_type': 'GDC', 'ppr_alpha': 0.05, 'reduction_factor': 10, 'regularise': False, 'reweight_attention': False, 'rewire_KNN': False, 'rewire_KNN_T': 'T0', 'rewire_KNN_epoch': 5, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'rewiring': None, 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'self_loop_weight': 0, 'sparsify': 'S_hat', 'square_plus': True, 'step_size': 1, 'symmetric_attention': False, 'threshold_type': 'addD_rvR', 'time': 3.126400580172773, 'tol_scale': 9348.983916372074, 'tol_scale_adjoint': 6599.1250595331385, 'total_deriv': None, 'use_cora_defaults': False, 'use_flux': False, 'use_labels': False, 'use_mlp': False},\n",
        "#                     'Computers': {'M_nodes': 64, 'adaptive': False, 'add_source': False, 'adjoint': True, 'adjoint_method': 'dopri5', 'adjoint_step_size': 1, 'alpha': 1.0, 'alpha_dim': 'sc', 'att_samp_pct': 0.572918052062338, 'attention_dim': 64, 'attention_norm_idx': 0, 'attention_rewiring': False, 'attention_type': 'scaled_dot', 'augment': False, 'baseline': False, 'batch_norm': False, 'beltrami': False, 'beta_dim': 'sc', 'block': 'hard_attention', 'cpus': 1, 'data_norm': 'rw', 'dataset': 'Computers', 'decay': 0.007674669913252157, 'directional_penalty': None, 'dropout': 0.08732611854459256, 'dt': 0.001, 'dt_min': 1e-05, 'epoch': 100, 'exact': False, 'fc_out': False, 'feat_hidden_dim': 64, 'function': 'laplacian', 'gdc_avg_degree': 64, 'gdc_k': 64, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_threshold': 0.01, 'gpus': 1.0, 'grace_period': 25, 'heads': 4, 'heat_time': 3.0, 'hidden_dim': 128, 'input_dropout': 0.5973137276937647, 'jacobian_norm2': None, 'kinetic_energy': None, 'label_rate': 0.5, 'leaky_relu_slope': 0.2, 'lr': 0.0035304663972281548, 'max_epochs': 1000, 'max_iters': 100, 'max_nfe': 500, 'method': 'dopri5', 'metric': 'accuracy', 'mix_features': False, 'name': 'computer_beltrami_hard_att1', 'new_edges': 'random', 'no_alpha_sigmoid': False, 'not_lcc': True, 'num_init': 1, 'num_samples': 400, 'num_splits': 2, 'ode_blocks': 1, 'optimizer': 'adam', 'patience': 100, 'pos_enc_hidden_dim': 32, 'pos_enc_orientation': 'row', 'pos_enc_type': 'DW128', 'ppr_alpha': 0.05, 'reduction_factor': 10, 'regularise': False, 'reweight_attention': False, 'rewire_KNN': False, 'rewire_KNN_T': 'T0', 'rewire_KNN_epoch': 10, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'rewiring': None, 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'self_loop_weight': 1.7138583550928912, 'sparsify': 'S_hat', 'square_plus': False, 'step_size': 1, 'threshold_type': 'addD_rvR', 'time': 3.249016177876166, 'tol_scale': 127.46369887079446, 'tol_scale_adjoint': 443.81436775321754, 'total_deriv': None, 'use_cora_defaults': False, 'use_flux': False, 'use_labels': False, 'use_mlp': False},\n",
        "#                     'Photo': {'M_nodes': 64, 'adaptive': False, 'add_source': False, 'adjoint': True, 'adjoint_method': 'rk4', 'adjoint_step_size': 1, 'alpha': 1.0, 'alpha_dim': 'sc', 'att_samp_pct': 0.9282359956104751, 'attention_dim': 64, 'attention_norm_idx': 0, 'attention_rewiring': False, 'attention_type': 'pearson', 'augment': False, 'baseline': False, 'batch_norm': True, 'beltrami': False, 'beta_dim': 'sc', 'block': 'hard_attention', 'cpus': 1, 'data_norm': 'rw', 'dataset': 'Photo', 'decay': 0.004707800883497945, 'directional_penalty': None, 'dropout': 0.46502284638600183, 'dt': 0.001, 'dt_min': 1e-05, 'epoch': 100, 'exact': False, 'fc_out': False, 'feat_hidden_dim': 64, 'function': 'laplacian', 'gdc_avg_degree': 64, 'gdc_k': 64, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_threshold': 0.01, 'gpus': 1.0, 'grace_period': 25, 'heads': 4, 'heat_time': 3.0, 'hidden_dim': 64, 'input_dropout': 0.42903126506740247, 'jacobian_norm2': None, 'kinetic_energy': None, 'label_rate': 0.5, 'leaky_relu_slope': 0.2, 'lr': 0.005560726683883279, 'max_epochs': 1000, 'max_iters': 100, 'max_nfe': 500, 'method': 'dopri5', 'metric': 'accuracy', 'mix_features': False, 'name': 'photo_beltrami_hard_att1', 'new_edges': 'random', 'no_alpha_sigmoid': False, 'not_lcc': True, 'num_init': 1, 'num_samples': 400, 'num_splits': 2, 'ode_blocks': 1, 'optimizer': 'adam', 'patience': 100, 'pos_enc_hidden_dim': 16, 'pos_enc_orientation': 'row', 'pos_enc_type': 'DW128', 'ppr_alpha': 0.05, 'reduction_factor': 10, 'regularise': False, 'reweight_attention': False, 'rewire_KNN': False, 'rewire_KNN_T': 'T0', 'rewire_KNN_epoch': 10, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'rewiring': None, 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'self_loop_weight': 0.05783612585280118, 'sparsify': 'S_hat', 'square_plus': False, 'step_size': 1, 'threshold_type': 'addD_rvR', 'time': 3.5824027975386623, 'tol_scale': 2086.525473167121, 'tol_scale_adjoint': 14777.606112557354, 'total_deriv': None, 'use_cora_defaults': False, 'use_flux': False, 'use_labels': False, 'use_mlp': False},\n",
        "#                     'ogbn-arxiv': {'M_nodes': 64, 'adaptive': False, 'add_source': False, 'adjoint': True, 'adjoint_method': 'rk4', 'adjoint_step_size': 1, 'alpha': 1.0, 'alpha_dim': 'sc', 'att_samp_pct': 0.8105268910037231, 'attention_dim': 32, 'attention_norm_idx': 0, 'attention_rewiring': False, 'attention_type': 'scaled_dot', 'augment': False, 'baseline': False, 'batch_norm': True, 'beltrami': False, 'beta_dim': 'sc', 'block': 'hard_attention', 'cpus': 1, 'data_norm': 'rw', 'dataset': 'ogbn-arxiv', 'decay': 0, 'directional_penalty': None, 'dropout': 0.11594990901233933, 'dt': 0.001, 'dt_min': 1e-05, 'epoch': 100, 'exact': False, 'fc_out': False, 'feat_hidden_dim': 64, 'function': 'laplacian', 'gdc_avg_degree': 64, 'gdc_k': 64, 'gdc_method': 'ppr', 'gdc_sparsification': 'topk', 'gdc_threshold': 0.01, 'gpus': 1.0, 'grace_period': 20, 'heads': 2, 'heat_time': 3.0, 'hidden_dim': 162, 'input_dropout': 0, 'jacobian_norm2': None, 'kinetic_energy': None, 'label_rate': 0.21964773835397075, 'leaky_relu_slope': 0.2, 'lr': 0.005451476553977102, 'max_epochs': 1000, 'max_iters': 100, 'max_nfe': 500, 'method': 'dopri5', 'metric': 'accuracy', 'mix_features': False, 'name': 'arxiv_beltrami_hard_att', 'new_edges': 'random', 'no_alpha_sigmoid': False, 'not_lcc': False, 'num_init': 2, 'num_samples': 200, 'num_splits': 1, 'ode_blocks': 1, 'optimizer': 'rmsprop', 'patience': 100, 'pos_enc_hidden_dim': 98, 'pos_enc_orientation': 'row', 'pos_enc_type': 'DW64', 'ppr_alpha': 0.05, 'reduction_factor': 10, 'regularise': False, 'reweight_attention': False, 'rewire_KNN': False, 'rewire_KNN_T': 'T0', 'rewire_KNN_epoch': 10, 'rewire_KNN_k': 64, 'rewire_KNN_sym': False, 'rewiring': None, 'rw_addD': 0.02, 'rw_rmvR': 0.02, 'self_loop_weight': 1, 'sparsify': 'S_hat', 'square_plus': False, 'step_size': 1, 'threshold_type': 'addD_rvR', 'time': 3.6760155951687636, 'tol_scale': 11353.558848254957, 'tol_scale_adjoint': 1.0, 'total_deriv': None, 'use_cora_defaults': False, 'use_flux': False, 'use_labels': False, 'use_lcc': True, 'use_mlp': False}\n",
        "#                     }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for other pc launch this\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aH6gIcdWvcGM"
      },
      "outputs": [],
      "source": [
        "opt = {'self_loop_weight': 1, 'leaky_relu_slope': 0.2, 'heads': 2, 'K': 10, 'not_lcc': True, 'dataset': 'Cora', 'force_reload': True,\n",
        "        'attention_norm_idx': 0, 'simple': True, 'alpha': 0, 'alpha_dim': 'sc', 'beta_dim': 'sc', \"use_labels\": True,\n",
        "        'hidden_dim': 64, 'block': 'attention', 'function': 'laplacian', 'alpha_sigmoid': True, 'augment': False, 'adjoint': False,\n",
        "        'tol_scale': 70, 'time': 20, 'input_dropout': 0.5, 'dropout': 0.2, 'method': 'dopri5', 'optimizer':'adam', 'lr':0.008, \"use_mlp\": True,\n",
        "        'decay':0.007, 'epoch':20, 'kinetic_energy':None, 'jacobian_norm2':None, 'total_deriv':None, 'directional_penalty':None, \"beltrami\": False}\n",
        "# best_opt = best_params_dict['Cora']\n",
        "# opt = {**default_args, **best_opt}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dHMiY6t7Stgg"
      },
      "outputs": [],
      "source": [
        "opt[\"fc_out\"] = False\n",
        "opt[\"batch_norm\"] = False\n",
        "opt[\"heads\"] = 8\n",
        "opt[\"attention_dim\"] = 128\n",
        "opt['attention_type'] = 'scaled_dot'\n",
        "opt['label_rate'] = 0.5\n",
        "opt['square_plus'] = True\n",
        "opt['reweight_attention'] = False\n",
        "opt['step_size'] = 1\n",
        "opt['max_nfe'] = 5000\n",
        "opt['no_alpha_sigmoid'] = False\n",
        "opt['add_source'] = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JoBfaO0tSodU"
      },
      "outputs": [],
      "source": [
        "def construct_graph(edges, attention=None, threshold=0.01):\n",
        "    if isinstance(edges, torch.Tensor):\n",
        "        edges = edges.cpu().numpy()\n",
        "    if attention is not None:\n",
        "        edges = edges[:, attention > threshold]\n",
        "    edge_list = zip(edges[0], edges[1])\n",
        "    g = nx.Graph(edge_list)\n",
        "    return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9C9nT-Y7Pt_k"
      },
      "outputs": [],
      "source": [
        "def add_noisy_edges(edge_index, num_nodes, noise_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Add random noisy edges to the graph.\n",
        "    \"\"\"\n",
        "    num_edges = edge_index.shape[1]\n",
        "    num_add = int(noise_ratio * num_edges)  # Number of noisy edges to add\n",
        "\n",
        "    added_edges = []\n",
        "    existing_edges = set(map(tuple, edge_index.t().tolist()))  # Convert edges to a set for lookup\n",
        "\n",
        "    while len(added_edges) < num_add:\n",
        "        # Pick two random nodes\n",
        "        u, v = random.randint(0, num_nodes - 1), random.randint(0, num_nodes - 1)\n",
        "\n",
        "        # Ensure it's a new edge and not a self-loop\n",
        "        if u != v and (u, v) not in existing_edges and (v, u) not in existing_edges:\n",
        "            added_edges.append((u, v))\n",
        "\n",
        "    # Convert to tensor and concatenate\n",
        "    print(f\"Edges added: {len(added_edges)}\")\n",
        "    new_edges = torch.tensor(added_edges, dtype=torch.long).t()\n",
        "    return torch.cat([edge_index, new_edges], dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "65GeNY5be7ar"
      },
      "outputs": [],
      "source": [
        "def add_labels(feat, labels, idx, num_classes, device):\n",
        "  onehot = torch.zeros([feat.shape[0], num_classes]).to(device)\n",
        "  if idx.dtype == torch.bool:\n",
        "    idx = torch.where(idx)[0]  # convert mask to linear index\n",
        "  onehot[idx, labels.squeeze()[idx]] = 1\n",
        "\n",
        "  return torch.cat([feat, onehot], dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GYHfKAxOBCEN"
      },
      "outputs": [],
      "source": [
        "def to_edge_set(edge_index):\n",
        "    # Convert [2, N] tensor to a set of sorted tuples (for undirected comparison)\n",
        "    return set(tuple(sorted((int(edge_index[0, i]), int(edge_index[1, i])))) for i in range(edge_index.size(1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XvMOJ6eXBS0I"
      },
      "outputs": [],
      "source": [
        "def score_edges(z, edge_pairs):\n",
        "    return (z[edge_pairs[0]] * z[edge_pairs[1]]).sum(dim=1)  #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "00pTnzj7qRoh"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(model, data, pos_encoding=None, opt=None):  # opt required for runtime polymorphism\n",
        "  model.eval()\n",
        "  feat = data.x\n",
        "  if model.opt['use_labels']:\n",
        "    feat = add_labels(feat, data.y, data.train_mask, model.num_classes, model.device)\n",
        "  logits, accs = model(feat, pos_encoding), []\n",
        "  for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "    pred = logits[mask].max(1)[1]\n",
        "    acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "    accs.append(acc)\n",
        "  return logits,accs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "epzKchya3x3z"
      },
      "outputs": [],
      "source": [
        "def draw_graph_after_adding_noise(dataset, added_edges):\n",
        "  # Convert to NetworkX\n",
        "  G = to_networkx(dataset.data)\n",
        "\n",
        "  # Add all nodes to ensure disconnected ones are included\n",
        "  G.add_nodes_from(range(dataset.data.num_nodes))\n",
        "\n",
        "  # Draw base graph\n",
        "  pos = nx.spring_layout(G, seed=42)\n",
        "  # nx.draw(G, pos, node_color=\"lightblue\", node_size=4, edge_color=\"gray\", width=0.5)\n",
        "\n",
        "\n",
        "  nx.draw(G, node_color=\"lightblue\", node_size=4, edge_color=\"gray\", width=0.5)\n",
        "\n",
        "\n",
        "  # Highlight the added (noisy) edges\n",
        "  added_edge_list = list(added_edges)\n",
        "  nx.draw_networkx_edges(\n",
        "      G,\n",
        "      pos,\n",
        "      edgelist=added_edge_list,\n",
        "      edge_color=\"red\",\n",
        "      width=1.5,\n",
        "      style=\"dashed\",\n",
        "      label=\"Noisy Edges\"\n",
        "  )\n",
        "\n",
        "  plt.title(\"Graph with Noisy (Added) Edges in Red\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vafbV9GgTZnC"
      },
      "outputs": [],
      "source": [
        "def prepare_data():\n",
        "  # Step 1: Prepare original edges\n",
        "  dataset = Planetoid(root='data', name='PubMed')\n",
        "  original_edges = dataset.data.edge_index\n",
        "\n",
        "  # Step 2: Remove a subset of edges\n",
        "  num_edges_to_remove = int(original_edges.size(1) * 0.25)\n",
        "  edge_indices = list(range(original_edges.size(1)))\n",
        "  random.shuffle(edge_indices)\n",
        "  removed_edge_indices = edge_indices[:num_edges_to_remove]\n",
        "  removed_edges = original_edges[:, removed_edge_indices]\n",
        "\n",
        "  # Step 3: Keep the remaining edges\n",
        "  remaining_edges = torch.cat(\n",
        "      [original_edges[:, i].unsqueeze(1) for i in edge_indices[num_edges_to_remove:]], dim=1\n",
        "  )\n",
        "\n",
        "  # Step 4: Update the graph for training\n",
        "  remaining_edges_to_verify = remaining_edges.clone()\n",
        "  dataset.data.edge_index = remaining_edges\n",
        "\n",
        "  # Step 5: Store deleted edges for later comparison\n",
        "  deleted_edges = {tuple(edge.tolist()) for edge in removed_edges.T}\n",
        "\n",
        "  print(\"Training edges:\", dataset.edge_index.shape)\n",
        "  print(\"Deleted edges:\", len(deleted_edges))\n",
        "  return dataset, removed_edges, remaining_edges_to_verify\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1qeq6AFaY28d"
      },
      "outputs": [],
      "source": [
        "# # Save the edge_index before adding noisy edges\n",
        "# edge_index_before = dataset.data.edge_index.clone()\n",
        "\n",
        "# # Add noisy edges\n",
        "# dataset.data.edge_index = add_noisy_edges(dataset.data.edge_index, num_nodes=dataset.data.num_nodes, noise_ratio=0.001)\n",
        "\n",
        "# # After adding noise\n",
        "# edge_index_after = dataset.data.edge_index\n",
        "\n",
        "# # Convert both to sets of tuples for easy comparison\n",
        "# before_edges = {tuple(edge.tolist()) for edge in edge_index_before.T}\n",
        "# after_edges = {tuple(edge.tolist()) for edge in edge_index_after.T}\n",
        "\n",
        "# # Find newly added edges\n",
        "# added_edges = after_edges - before_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSv_zdocKtP5"
      },
      "outputs": [],
      "source": [
        "# draw_graph_after_adding_noise(dataset, added_edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YIZIvNo_yz1y"
      },
      "outputs": [],
      "source": [
        "def trainModel(opt, dataset):\n",
        "  model, dat = GNN(opt, dataset, device).to(device), dataset.data.to(device)\n",
        "  parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "  optimizer = get_optimizer(opt['optimizer'], parameters, lr=opt['lr'], weight_decay=opt['decay'])\n",
        "\n",
        "  best_val_acc = test_acc = best_epoch = 0\n",
        "  # we are training the model on the remaning dataset\n",
        "  for epoch in range(1, opt['epoch']):\n",
        "      start_time = time.time()\n",
        "\n",
        "      loss = train(model, optimizer, dat)\n",
        "      train_acc, val_acc, tmp_test_acc = test_model(model, dat)\n",
        "\n",
        "      if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        test_acc = tmp_test_acc\n",
        "        best_epoch = epoch\n",
        "      log = 'Epoch: {:03d}, Runtime {:03f}, Loss {:03f}, forward nfe {:d}, backward nfe {:d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
        "      print(\n",
        "        log.format(epoch, time.time() - start_time, loss, model.fm.sum, model.bm.sum, train_acc, best_val_acc, test_acc))\n",
        "      print('best val accuracy {:03f} with test accuracy {:03f} at epoch {:d}'.format(best_val_acc, test_acc, best_epoch))\n",
        "      return model, dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3KfhilmTcKC"
      },
      "outputs": [],
      "source": [
        "# model, dat = GNN(opt, data    set, device).to(device), dataset.data.to(device)\n",
        "# parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "# optimizer = get_optimizer(opt['optimizer'], parameters, lr=opt['lr'], weight_decay=opt['decay'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spw31Bn4TpUU"
      },
      "outputs": [],
      "source": [
        "# best_val_acc = test_acc = best_epoch = 0\n",
        "# # we are training the model on the remaning dataset\n",
        "# for epoch in range(1, opt['epoch']):\n",
        "#     start_time = time.time()\n",
        "\n",
        "#     loss = train(model, optimizer, dat)\n",
        "#     train_acc, val_acc, tmp_test_acc = test_model(model, dat)\n",
        "\n",
        "#     if val_acc > best_val_acc:\n",
        "#       best_val_acc = val_acc\n",
        "#       test_acc = tmp_test_acc\n",
        "#       best_epoch = epoch\n",
        "#     log = 'Epoch: {:03d}, Runtime {:03f}, Loss {:03f}, forward nfe {:d}, backward nfe {:d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
        "#     print(\n",
        "#       log.format(epoch, time.time() - start_time, loss, model.fm.sum, model.bm.sum, train_acc, best_val_acc, test_acc))\n",
        "#     print('best val accuracy {:03f} with test accuracy {:03f} at epoch {:d}'.format(best_val_acc, test_acc, best_epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TDMcO7m_NTJ"
      },
      "outputs": [],
      "source": [
        "# G = to_networkx(dataset.data)\n",
        "# print(\"Nodes in NetworkX graph:\", G.number_of_nodes())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUo7LRtzGZ7Y"
      },
      "outputs": [],
      "source": [
        "# from collections import defaultdict\n",
        "\n",
        "# removed_edges_set = set(tuple(sorted((int(u), int(v)))) for u, v in zip(removed_edges[0], removed_edges[1]))\n",
        "\n",
        "# reconstruction_counter = defaultdict(int)\n",
        "# total_tests = 45 #number of loops to test 45 is max as tested\n",
        "# reconstructed_edges_list = []\n",
        "# new_predicted_counter = defaultdict(int)\n",
        "# new_predicted_counter = defaultdict(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2bJIrLcjXw1"
      },
      "outputs": [],
      "source": [
        "# all_pairs = torch.combinations(torch.arange(G.number_of_nodes()), r=2).T  # shape: [2, num_pairs]\n",
        "\n",
        "\n",
        "# known_edges = to_edge_set(dat.x)\n",
        "# all_edges_set = set(tuple(sorted((int(u), int(v)))) for u, v in zip(all_pairs[0], all_pairs[1]))\n",
        "# candidate_edges = list(all_edges_set - known_edges)\n",
        "\n",
        "# # Convert back to tensor\n",
        "# candidate_edge_index = torch.tensor(candidate_edges).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9ShXeAjv-2kf"
      },
      "outputs": [],
      "source": [
        "def generate_and_delete_reconstructed_edges():\n",
        "      # delete new predict and removed one\n",
        "    dataset, removed_edges, _ = prepare_data()\n",
        "    removed_edges_set = set(tuple(sorted((int(u), int(v)))) for u, v in zip(removed_edges[0], removed_edges[1]))\n",
        "    # dataset.data.edge_index = add_noisy_edges(dataset.data.edge_index, num_nodes=dataset.data.num_nodes, noise_ratio=0.001)\n",
        "    return dataset, removed_edges_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "04DwucwkvD_v"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "def score_edges(embeddings, edge_index):\n",
        "    u = embeddings[edge_index[0]]\n",
        "    v = embeddings[edge_index[1]]\n",
        "    return F.cosine_similarity(u, v)  # returns score per edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "416z0_BW9tpq"
      },
      "outputs": [],
      "source": [
        "def is_close_enough(embeddings, edge_index, epsilon=0.05):\n",
        "    u = embeddings[edge_index[0]]\n",
        "    v = embeddings[edge_index[1]]\n",
        "    distances = torch.norm(u - v, dim=1)\n",
        "    return distances <= epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u1FuvPgBRtH"
      },
      "outputs": [],
      "source": [
        "# from collections import defaultdict\n",
        "# opt[\"max_nfe\"] = 15000\n",
        "# total_tests = 10\n",
        "# for i in range(total_tests):\n",
        "#     dataset, removed_edges_set = generate_and_delete_reconstructed_edges()\n",
        "#     model, dat = trainModel(opt, dataset)\n",
        "#     G = to_networkx(dataset.data)\n",
        "#     print(\"Nodes in NetworkX graph:\", G.number_of_nodes())\n",
        "#     removed_edges_set = set(tuple(sorted((int(u), int(v)))) for u, v in zip(removed_edges[0], removed_edges[1]))\n",
        "\n",
        "#     reconstruction_counter = defaultdict(int)\n",
        "#     total_tests = 45 #number of loops to test 45 is max as tested\n",
        "#     reconstructed_edges_list = []\n",
        "#     new_predicted_counter = defaultdict(int)\n",
        "#     new_predicted_counter = defaultdict(int)\n",
        "\n",
        "\n",
        "#     all_pairs = torch.combinations(torch.arange(G.number_of_nodes()), r=2).T  # shape: [2, num_pairs]\n",
        "\n",
        "\n",
        "#     known_edges = to_edge_set(dat.x)\n",
        "#     all_edges_set = set(tuple(sorted((int(u), int(v)))) for u, v in zip(all_pairs[0], all_pairs[1]))\n",
        "#     candidate_edges = list(all_edges_set - known_edges)\n",
        "\n",
        "#     # Convert back to tensor\n",
        "#     candidate_edge_index = torch.tensor(candidate_edges).T\n",
        "\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         # dataset,removed_edges_set = generate_and_delete_reconstructed_edges()\n",
        "#         # dat = dataset.data.to(device)\n",
        "#         feat = dat.x # Use dat.x instead, which has shape [num_nodes, num_features]\n",
        "#         feat = add_labels(feat, dat.y, dat.train_mask, model.num_classes, model.device)\n",
        "#         node_embeddings = model(feat, None)\n",
        "\n",
        "#         # Generate candidate edges (or all pairs) and score\n",
        "#         # TODO - take score that at least 95, instead of score 100\n",
        "#         # TODO - take the distance from each vector, and verify the distance is lower than epsilon\n",
        "#         scores = score_edges(node_embeddings, candidate_edge_index)\n",
        "#         top_scores, top_indices = scores.topk(100)\n",
        "#         predicted_edges = candidate_edge_index[:, top_indices]\n",
        "#         # Compare to removed edges\n",
        "#         for u, v in zip(predicted_edges[0], predicted_edges[1]):\n",
        "#             edge = tuple(sorted((int(u), int(v))))\n",
        "#             if edge in removed_edges_set:\n",
        "#                 reconstruction_counter[edge] += 1\n",
        "#                 reconstructed_edges_list.append(edge)\n",
        "#             else:\n",
        "#                 new_predicted_counter[edge] += 1\n",
        "#         if len(reconstruction_counter) and len(new_predicted_counter):\n",
        "#           print(f\"Round {i + 1}, total removed reconstructed: {len(reconstruction_counter.keys())}, total new reconstructed: {len(new_predicted_counter.keys())}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK7gilrYWl4F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training edges: torch.Size([2, 66486])\n",
            "Deleted edges: 22162\n",
            "Training edges: torch.Size([2, 66486])\n",
            "Deleted edges: 22162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:15: UserWarning: Dopri5Solver: Unexpected arguments {'step_size': 1}\n",
            "  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "dataset, removed_edges = generate_and_delete_reconstructed_edges()\n",
        "G = to_networkx(dataset.data)\n",
        "\n",
        "opt[\"max_nfe\"] = 5000\n",
        "total_tests = 100  # Initial number of test rounds\n",
        "epsilon = 0.01     # Distance threshold for edge prediction\n",
        "score_threshold = 95  # Score threshold for filtering predicted edges\n",
        "\n",
        "known_edges = to_edge_set(dataset.x)\n",
        "\n",
        "reconstruction_counter = defaultdict(int)\n",
        "reconstructed_edges_list = []\n",
        "new_predicted_counter = defaultdict(int)\n",
        "\n",
        "num_samples = 50000\n",
        "all_possible = torch.combinations(torch.arange(G.number_of_nodes()), r=2)\n",
        "perm = torch.randperm(all_possible.size(0))[:num_samples]\n",
        "sampled_pairs = all_possible[perm]\n",
        "candidate_edge_index = sampled_pairs.T\n",
        "\n",
        "\n",
        "for i in range(total_tests):\n",
        "    dataset, removed_edges = generate_and_delete_reconstructed_edges()\n",
        "    model, dat = trainModel(opt, dataset)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        feat = dat.x\n",
        "        feat = add_labels(feat, dat.y, dat.train_mask, model.num_classes, model.device)\n",
        "        node_embeddings = model(feat, None)\n",
        "\n",
        "        # Score all candidate edges (e.g., using cosine or dot-product)\n",
        "        scores = score_edges(node_embeddings, candidate_edge_index)\n",
        "\n",
        "        # (Optional) Score filtering - top 10% most confident scores\n",
        "        threshold_value = torch.quantile(scores, 0.90)\n",
        "        high_score_mask = scores >= threshold_value\n",
        "        high_score_edges = candidate_edge_index[:, high_score_mask]\n",
        "\n",
        "        # Distance-based filtering\n",
        "        distances = torch.norm(\n",
        "            node_embeddings[high_score_edges[0]] - node_embeddings[high_score_edges[1]], dim=1\n",
        "        )\n",
        "        close_mask = distances <= epsilon\n",
        "\n",
        "        predicted_edges = high_score_edges[:, close_mask]\n",
        "\n",
        "        print(\"\\n\\nScore range:\", scores.min().item(), \"-\", scores.max().item())\n",
        "        print(\"Distance range:\", distances.min().item(), \"-\", distances.max().item())\n",
        "\n",
        "        # Compare predicted edges to removed edges\n",
        "        for u, v in zip(predicted_edges[0], predicted_edges[1]):\n",
        "            edge = tuple(sorted((int(u), int(v))))\n",
        "            if edge in removed_edges:\n",
        "                reconstruction_counter[edge] += 1\n",
        "                reconstructed_edges_list.append(edge)\n",
        "            else:\n",
        "                new_predicted_counter[edge] += 1\n",
        "\n",
        "        if len(reconstruction_counter) and len(new_predicted_counter):\n",
        "            print(f\"\\nRound {i + 1}, total removed reconstructed: {len(reconstruction_counter.keys())}, \"\n",
        "                  f\"total new reconstructed: {len(new_predicted_counter.keys())}\"\n",
        "                  f\"TOTAL WEAK EDGES in round: {len(predicted_edges.keys())-len(reconstruction_counter.keys()-len(new_predicted_counter.keys()))}\")\n",
        "        print(\"\\n ******************************************* \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lFDWKsWHHewo"
      },
      "outputs": [],
      "source": [
        "reconstruction_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ozw7IQldBkaL"
      },
      "outputs": [],
      "source": [
        "scores = score_edges(node_embeddings, candidate_edge_index)\n",
        "top_k = 100\n",
        "topk_indices = scores.topk(top_k).indices\n",
        "predicted_edges = candidate_edge_index[:, topk_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYuIxgODG54t"
      },
      "outputs": [],
      "source": [
        "# Display the graph of reconstructed edges\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "new_labels = []\n",
        "new_counts = []\n",
        "recovered_labels = []\n",
        "recovered_counts = []\n",
        "\n",
        "for edge, count in reconstruction_counter.items():\n",
        "    label = f\"{edge[0]}-{edge[1]}\"\n",
        "    recovered_labels.append(label)\n",
        "    recovered_counts.append(count)\n",
        "\n",
        "for edge, count in new_predicted_counter.items():\n",
        "    label = f\"{edge[0]}-{edge[1]}\"\n",
        "    new_labels.append(label)\n",
        "    new_counts.append(count)\n",
        "# Plotly bar chart\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=recovered_labels,\n",
        "    y=recovered_counts,\n",
        "    name='Recovered (Originally Removed)',\n",
        "    marker_color='cornflowerblue'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=new_labels,\n",
        "    y=new_counts,\n",
        "    name='New Predicted (Not Originally Present)',\n",
        "    marker_color='orange'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Edge Reconstruction vs New Predictions\",\n",
        "    xaxis_title=\"Edge (u-v)\",\n",
        "    yaxis_title=\"Reconstruction Count\",\n",
        "    barmode='group',\n",
        "    xaxis_tickangle=-45,\n",
        "    template='plotly_white',\n",
        "    margin=dict(l=40, r=40, t=60, b=100)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4yhkTecodkp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a dictionary from the lists\n",
        "data = {\n",
        "    'Edge': recovered_labels + new_labels,\n",
        "    'Count': recovered_counts + new_counts,\n",
        "    'Type': ['Recovered'] * len(recovered_labels) + ['New Predicted'] * len(new_labels)\n",
        "}\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('edge_reconstruction_data.csv', index=False)\n",
        "\n",
        "print(\"Data saved to edge_reconstruction_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvR0R1z2LGP1"
      },
      "outputs": [],
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "# Create PyVis network\n",
        "net = Network(notebook=False, height=\"750px\", width=\"100%\", bgcolor=\"#ffffff\", font_color=\"black\")\n",
        "\n",
        "# Add graph from networkx\n",
        "net.from_nx(G)\n",
        "\n",
        "# Highlight reconstructed edges in red\n",
        "for u, v in reconstructed:\n",
        "    net.add_edge(int(u), int(v), color='red', width=10)\n",
        "\n",
        "# Optional: change node size or color\n",
        "for node in G.nodes():\n",
        "    net.get_node(node)['size'] = 10\n",
        "    net.get_node(node)['color'] = \"#cccccc\"\n",
        "\n",
        "# Save and open in browser\n",
        "net.save_graph(\"graph_reconstruction.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8NVMyaeZZbC"
      },
      "outputs": [],
      "source": [
        "total_data_to_review = [\n",
        "  {\n",
        "    \"iteration\": 1,\n",
        "    \"total_deleted\": 300,\n",
        "    \"total_reconstructed\": 180,\n",
        "    \"new_reconstructed\": 50\n",
        "  },\n",
        "  {\n",
        "    \"iteration\": 2,\n",
        "    \"total_deleted\": 300,\n",
        "    \"total_reconstructed\": 200,\n",
        "    \"new_reconstructed\": 45\n",
        "  },\n",
        "  {\n",
        "    \"iteration\": 3,\n",
        "    \"total_deleted\": 300,\n",
        "    \"total_reconstructed\": 190,\n",
        "    \"new_reconstructed\": 55\n",
        "  }\n",
        "]\n",
        "\n",
        "# Extract values\n",
        "iterations = [entry[\"iteration\"] for entry in total_data_to_review]\n",
        "deleted = [entry[\"total_deleted\"] for entry in total_data_to_review]\n",
        "reconstructed = [entry[\"total_reconstructed\"] for entry in total_data_to_review]\n",
        "new_reconstructed = [entry[\"new_reconstructed\"] for entry in total_data_to_review]\n",
        "\n",
        "# Bar chart setup\n",
        "bar_width = 0.25\n",
        "x = np.arange(len(iterations))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Bars\n",
        "plt.bar(x - bar_width, deleted, width=bar_width, label='Total Deleted')\n",
        "plt.bar(x, reconstructed, width=bar_width, label='Total Reconstructed')\n",
        "plt.bar(x + bar_width, new_reconstructed, width=bar_width, label='New Reconstructed')\n",
        "\n",
        "# Labels and ticks\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Number of Edges\")\n",
        "plt.title(\"Edge Reconstruction Metrics Per Iteration\")\n",
        "plt.xticks(x, [f\"Iter {i}\" for i in iterations])\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuARNTWjukwJ"
      },
      "outputs": [],
      "source": [
        "# %80 %20 - accuracy best\n",
        "# %70 %30 - accuracy best\n",
        "# ....\n",
        "# 85% %15 - ....\n",
        "\n",
        "\n",
        "# removed edges -> evaluations\n",
        "# delete_reconstructed....\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2b_h-mEpDBe"
      },
      "outputs": [],
      "source": [
        "def get_node_embeddings(model, data):\n",
        "    \"\"\"Extract final node embeddings from the GNN model\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # If use_labels is True, add labels to features before passing to the model\n",
        "        if model.opt['use_labels']:\n",
        "            x = add_labels(data.x, data.y, data.train_mask, model.num_classes, model.device)\n",
        "        else:\n",
        "            x = data.x\n",
        "\n",
        "        # Get model output, handle single or multiple outputs\n",
        "        output = model(x, None)\n",
        "\n",
        "        # If only embeddings are returned, unpack accordingly\n",
        "        if isinstance(output, torch.Tensor):\n",
        "            embeddings = output\n",
        "        # If multiple outputs are returned, unpack as before\n",
        "        else:\n",
        "            embeddings, _ = output\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "def calculate_confidence(embeddings, edge_index):\n",
        "    \"\"\"Calculate cosine similarity between connected nodes\"\"\"\n",
        "    src_emb = embeddings[edge_index[0]]\n",
        "    dst_emb = embeddings[edge_index[1]]\n",
        "    confidence = torch.cosine_similarity(src_emb, dst_emb).numpy()\n",
        "    return (edge_index.numpy(), confidence)\n",
        "\n",
        "def draw_confidence_graph(edges, confidence, threshold=0.5):\n",
        "    \"\"\"Draw graph with confidence-colored edges\"\"\"\n",
        "    G = nx.Graph()\n",
        "    edge_list = []\n",
        "\n",
        "    for i in range(edges.shape[1]):\n",
        "        if confidence[i] > threshold:\n",
        "            edge_list.append((edges[0,i], edges[1,i],\n",
        "                           {'confidence': confidence[i]}))\n",
        "\n",
        "    G.add_edges_from(edge_list)\n",
        "\n",
        "    pos = nx.spring_layout(G)\n",
        "    edge_colors = [d['confidence'] for _,_,d in G.edges(data=True)]\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "    nx.draw(G, pos, node_size=20,\n",
        "            edge_color=edge_colors, edge_cmap=plt.cm.Reds,\n",
        "            width=1.5, arrows=False)\n",
        "    plt.title(\"Reconstructed Edges with Confidence Scores\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45SKdA-Fwh5v"
      },
      "outputs": [],
      "source": [
        "# After training the model\n",
        "embeddings = get_node_embeddings(model, dataset.data)\n",
        "edges, confidence = calculate_confidence(embeddings, dataset.data.edge_index)\n",
        "\n",
        "# Visualize high-confidence edges (threshold=0.7)\n",
        "draw_confidence_graph(edges, confidence, threshold=0.7)\n",
        "\n",
        "# Compare with original graph\n",
        "draw_graph_after_adding_noise(dataset, edges.T)  # Existing visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN-kE5vg3z5_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_node_embeddings(model, data):\n",
        "    \"\"\"Extract final node embeddings from the GNN model\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # If use_labels is True, add labels to features before passing to the model\n",
        "        if model.opt['use_labels']:\n",
        "            x = add_labels(data.x, data.y, data.train_mask, model.num_classes, model.device)\n",
        "        else:\n",
        "            x = data.x\n",
        "\n",
        "        # Get model output, handle single or multiple outputs\n",
        "        output = model(x, None)\n",
        "\n",
        "        # If only embeddings are returned, unpack accordingly\n",
        "        if isinstance(output, torch.Tensor):\n",
        "            embeddings = output\n",
        "        # If multiple outputs are returned, unpack as before\n",
        "        else:\n",
        "            embeddings, _ = output\n",
        "    return embeddings\n",
        "\n",
        "def calculate_confidence(embeddings, edge_index):\n",
        "    \"\"\"Calculate cosine similarity between connected nodes\"\"\"\n",
        "    src_emb = embeddings[edge_index[0]]\n",
        "    dst_emb = embeddings[edge_index[1]]\n",
        "    scores = score_edges(node_embeddings, candidate_edge_index)  # Already used\n",
        "    top_scores, top_indices = scores.topk(100)\n",
        "    predicted_edges = candidate_edge_index[:, top_indices]\n",
        "    confidence = top_scores.cpu().numpy()\n",
        "    return (edge_index.numpy(), confidence)\n",
        "\n",
        "def draw_confidence_graph(edges, confidence, original_edge_index=None, threshold=None, figsize=(12, 16)):\n",
        "    \"\"\"\n",
        "    Draw graph with confidence-colored edges and show a matching histogram\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    edges : numpy.ndarray\n",
        "        Edge list with shape (2, num_edges) for reconstructed edges\n",
        "    confidence : numpy.ndarray\n",
        "        Confidence scores for each edge\n",
        "    original_edge_index : torch.Tensor or numpy.ndarray, optional\n",
        "        The original edge indices from the dataset\n",
        "    threshold : float or None\n",
        "        If provided, shows a line at this threshold in the histogram\n",
        "        and will be used as the minimum value for the colormap\n",
        "    figsize : tuple\n",
        "        Figure size for the plot (width, height)\n",
        "    \"\"\"\n",
        "    # Create figure with stacked subplots - graph on top (larger), histogram below\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize,\n",
        "                                  gridspec_kw={'height_ratios': [3, 1]})  # 3:1 ratio favoring the graph\n",
        "\n",
        "    # Build the graph with ALL confidence values (no filtering)\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Convert original edge indices to set for fast lookup if provided\n",
        "    original_edges_set = set()\n",
        "    if original_edge_index is not None:\n",
        "        if isinstance(original_edge_index, torch.Tensor):\n",
        "            original_edge_index = original_edge_index.numpy()\n",
        "\n",
        "        for i in range(original_edge_index.shape[1]):\n",
        "            # Add both directions (undirected graph)\n",
        "            edge = (original_edge_index[0, i], original_edge_index[1, i])\n",
        "            original_edges_set.add(edge)\n",
        "            original_edges_set.add(edge[::-1])  # Add reverse edge too\n",
        "\n",
        "    # Separate edges into original (existing) and reconstructed\n",
        "    original_edge_tuples = []\n",
        "    reconstructed_edge_tuples = []\n",
        "    reconstructed_confidence = []\n",
        "\n",
        "    if isinstance(edges, torch.Tensor):\n",
        "        edges = edges.numpy()\n",
        "\n",
        "\n",
        "    for i in range(edges.shape[1]):\n",
        "        u, v = edges[0, i], edges[1, i]\n",
        "        current_edge_tuple = tuple(sorted((int(u), int(v)))) # Ensure consistent edge representation\n",
        "\n",
        "        if original_edge_index is not None and current_edge_tuple in original_edges_set:\n",
        "            # This edge exists in the original graph\n",
        "            original_edge_tuples.append((u, v))\n",
        "        else:\n",
        "            # This is a reconstructed or potentially new edge\n",
        "            reconstructed_edge_tuples.append((u, v))\n",
        "            reconstructed_confidence.append(confidence[i])  # Append the confidence score\n",
        "\n",
        "    # Add all unique edges to the graph first\n",
        "    all_unique_edges = list(set(original_edge_tuples + reconstructed_edge_tuples))\n",
        "    G.add_edges_from(all_unique_edges)\n",
        "\n",
        "    # Add attributes to the reconstructed edges\n",
        "    for i, edge in enumerate(reconstructed_edge_tuples):\n",
        "        u, v = edge\n",
        "        G[u][v]['confidence'] = reconstructed_confidence[i]\n",
        "        G[u][v]['original'] = False # Explicitly mark as not original\n",
        "\n",
        "    # Add attribute to original edges (if needed for later use)\n",
        "    for u, v in original_edge_tuples:\n",
        "         # Check if the edge exists before adding attribute\n",
        "         if G.has_edge(u, v):\n",
        "             G[u][v]['original'] = True\n",
        "\n",
        "\n",
        "    # Set up color mapping for reconstructed edges\n",
        "    cmap = plt.cm.viridis  # Using viridis colormap (can be changed to Reds, etc.)\n",
        "\n",
        "    # Set colormap boundaries for reconstructed edges\n",
        "    if reconstructed_confidence:  # Only if we have reconstructed edges\n",
        "        if threshold is not None:\n",
        "            vmin = threshold\n",
        "        else:\n",
        "            vmin = min(reconstructed_confidence)\n",
        "        vmax = max(reconstructed_confidence)\n",
        "    else:\n",
        "        vmin, vmax = 0, 1  # Default if no reconstructed edges\n",
        "\n",
        "    norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
        "\n",
        "    # Draw the graph on the top subplot (larger area)\n",
        "    pos = nx.spring_layout(G, seed=42)  # Fixed seed for reproducibility\n",
        "\n",
        "    # Draw nodes\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=2, node_color='gray', ax=ax1)\n",
        "\n",
        "    # Draw original edges in black\n",
        "    original_edges_to_draw = [(u, v) for u, v, d in G.edges(data=True) if d.get('original', False)]\n",
        "    if original_edges_to_draw:\n",
        "        nx.draw_networkx_edges(G, pos,\n",
        "                             edgelist=original_edges_to_draw,\n",
        "                             edge_color='black',\n",
        "                             width=0.2,\n",
        "                             alpha=0.9,\n",
        "                             ax=ax1,\n",
        "                             label='Original Edges')\n",
        "\n",
        "    # Draw reconstructed edges with confidence colors\n",
        "    reconstructed_edges_to_draw = [(u, v) for u, v, d in G.edges(data=True) if not d.get('original', True) and 'confidence' in d]\n",
        "    if reconstructed_edges_to_draw:\n",
        "        edge_colors = [G[u][v]['confidence'] for u, v in reconstructed_edges_to_draw]\n",
        "        nx.draw_networkx_edges(G, pos,\n",
        "                             edgelist=reconstructed_edges_to_draw,\n",
        "                             edge_color=edge_colors,\n",
        "                             edge_cmap=cmap,\n",
        "                             edge_vmin=vmin,\n",
        "                             edge_vmax=vmax,\n",
        "                             width=3.5,\n",
        "                             alpha=0.7,\n",
        "                             ax=ax1,\n",
        "                             label='Reconstructed Edges')\n",
        "\n",
        "        # Add a colorbar for edge confidence\n",
        "        sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
        "        sm.set_array([])\n",
        "        cbar = fig.colorbar(sm, ax=ax1, label='Confidence Score', orientation='vertical',\n",
        "                           pad=0.01, fraction=0.05)\n",
        "\n",
        "    ax1.set_title(\"Graph with Original (Black) and Reconstructed (Colored) Edges\", fontsize=14)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Add legend for edge types\n",
        "    # Check if both types of edges were drawn before adding legend\n",
        "    if original_edges_to_draw or reconstructed_edges_to_draw:\n",
        "        from matplotlib.lines import Line2D\n",
        "        legend_elements = []\n",
        "        if original_edges_to_draw:\n",
        "             legend_elements.append(Line2D([0], [0], color='black', lw=4, label='Original Edges'))\n",
        "        if reconstructed_edges_to_draw:\n",
        "             # Using cmap(0.5) gives an intermediate color from the colormap for the legend\n",
        "             legend_elements.append(Line2D([0], [0], color=cmap(0.5 if reconstructed_confidence else 0), lw=3.5, label='Reconstructed Edges'))\n",
        "        if legend_elements:\n",
        "            ax1.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "\n",
        "    # Draw the histogram on the bottom subplot for reconstructed edge confidence\n",
        "    if reconstructed_confidence:\n",
        "        bins = np.linspace(min(reconstructed_confidence), max(reconstructed_confidence), 20)\n",
        "        ax2.hist(reconstructed_confidence, bins=bins, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "        ax2.set_title(\"Distribution of Reconstructed Edge Confidence Scores\", fontsize=12)\n",
        "        ax2.set_xlabel(\"Confidence Score\")\n",
        "        ax2.set_ylabel(\"Frequency\")\n",
        "        ax2.grid(alpha=0.3)\n",
        "\n",
        "        # Add vertical line for threshold if provided\n",
        "        if threshold is not None:\n",
        "            ax2.axvline(x=threshold, color='red', linestyle='--', label=f'Threshold: {threshold:.2f}') # Format threshold for clarity\n",
        "            ax2.legend()\n",
        "\n",
        "        # Add statistics to the histogram plot\n",
        "        avg_confidence = np.mean(reconstructed_confidence)\n",
        "        median_confidence = np.median(reconstructed_confidence)\n",
        "\n",
        "        # Add statistics to the histogram plot\n",
        "        avg_confidence = np.mean(reconstructed_confidence)\n",
        "        median_confidence = np.median(reconstructed_confidence)\n",
        "\n",
        "        stats_text = (f\"Statistics (Reconstructed Edges):\\n\"\n",
        "                     f\"Mean: {avg_confidence:.3f}\\n\"\n",
        "                     f\"Median: {median_confidence:.3f}\\n\"\n",
        "                     f\"Min: {min(reconstructed_confidence):.3f}\\n\"\n",
        "                     f\"Max: {max(reconstructed_confidence):.3f}\\n\"\n",
        "                     f\"Edges: {len(reconstructed_confidence)}\")\n",
        "\n",
        "        ax2.text(0.05, 0.95, stats_text, transform=ax2.transAxes,\n",
        "                 verticalalignment='top', bbox=dict(boxstyle='round', alpha=0.1))\n",
        "    else:\n",
        "        ax2.text(0.5, 0.5, \"No reconstructed edges to display\",\n",
        "                 transform=ax2.transAxes, ha='center', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig, (ax1, ax2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u9TT3Gn3059"
      },
      "outputs": [],
      "source": [
        "# After training the model\n",
        "embeddings = get_node_embeddings(model, dataset.data)\n",
        "edges, confidence = calculate_confidence(embeddings, dataset.data.edge_index)\n",
        "\n",
        "# Visualize with the new function including original edge information\n",
        "fig, (graph_ax, hist_ax) = draw_confidence_graph(\n",
        "    edges,\n",
        "    confidence,\n",
        "    original_edge_index=dataset.data.edge_index,  # Pass original edges\n",
        "    threshold=0.1\n",
        ")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
